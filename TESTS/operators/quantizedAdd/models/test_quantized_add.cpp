// Auto generated by utensor-cli

#include "uTensor/loaders/tensorIdxImporter.hpp"
#include "uTensor/core/tensor.hpp"
#include "uTensor/ops/ArrayOps.hpp"
#include "uTensor/core/context.hpp"
#include "uTensor/ops/MathOps.hpp"
#include "test_quantized_add.hpp"


void get_test_quantized_add_ctx(Context& ctx) {
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/test_quantized_add/x_1_0.idx"),
            "x_1:0",
            2);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/test_quantized_add/z_eightbit_x_reshape_dims_0.idx"),
            "z_eightbit/x/reshape_dims:0",
            1);
}
{
    ctx.add(new RamTensor<float>(), "z_eightbit/x/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "x_1:0", "z_eightbit/x/reshape_dims:0" },
             { "z_eightbit/x/reshape:0" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/test_quantized_add/z_eightbit_x_reduction_dims_0.idx"),
            "z_eightbit/x/reduction_dims:0",
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "z_eightbit/x/min:0", 1);
    ctx.push(new MinOp(), 
             { "z_eightbit/x/reshape:0", "z_eightbit/x/reduction_dims:0" },
             { "z_eightbit/x/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "z_eightbit/x/max:0", 1);
    ctx.push(new MaxOp(), 
             { "z_eightbit/x/reshape:0", "z_eightbit/x/reduction_dims:0" },
             { "z_eightbit/x/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "z_eightbit/x/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "z_eightbit/x/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "z_eightbit/x/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "x_1:0",  "z_eightbit/x/min:0", "z_eightbit/x/max:0" },
             {  "z_eightbit/x/quantize:0",  "z_eightbit/x/quantize:1", "z_eightbit/x/quantize:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/test_quantized_add/y_1_0.idx"),
            "y_1:0",
            2);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/test_quantized_add/z_eightbit_y_reshape_dims_0.idx"),
            "z_eightbit/y/reshape_dims:0",
            1);
}
{
    ctx.add(new RamTensor<float>(), "z_eightbit/y/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "y_1:0", "z_eightbit/y/reshape_dims:0" },
             { "z_eightbit/y/reshape:0" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/test_quantized_add/z_eightbit_y_reduction_dims_0.idx"),
            "z_eightbit/y/reduction_dims:0",
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "z_eightbit/y/min:0", 1);
    ctx.push(new MinOp(), 
             { "z_eightbit/y/reshape:0", "z_eightbit/y/reduction_dims:0" },
             { "z_eightbit/y/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "z_eightbit/y/max:0", 1);
    ctx.push(new MaxOp(), 
             { "z_eightbit/y/reshape:0", "z_eightbit/y/reduction_dims:0" },
             { "z_eightbit/y/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "z_eightbit/y/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "z_eightbit/y/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "z_eightbit/y/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "y_1:0",  "z_eightbit/y/min:0", "z_eightbit/y/max:0" },
             {  "z_eightbit/y/quantize:0",  "z_eightbit/y/quantize:1", "z_eightbit/y/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "z/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "z/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "z/eightbit:2", 2);
    ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
             { "z_eightbit/x/quantize:0", "z_eightbit/x/quantize:1", "z_eightbit/x/quantize:2", "z_eightbit/y/quantize:0", "z_eightbit/y/quantize:1",  "z_eightbit/y/quantize:2" },
             { "z/eightbit:0", "z/eightbit:1",  "z/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "z/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "z/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "z/eightbit:0", "z/eightbit:1", "z/eightbit:2" },
             { "z/eightbit/requant_range:0", "z/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "z/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "z/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "z/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "z/eightbit:0", "z/eightbit:1", "z/eightbit:2", "z/eightbit/requant_range:0", "z/eightbit/requant_range:1" },
             { "z/eightbit/requantize:0", "z/eightbit/requantize:1", "z/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>(), "z_1:0");
    ctx.push(new DequantizeOp(), 
             { "z/eightbit/requantize:0", "z/eightbit/requantize:1", "z/eightbit/requantize:2" },
             { "z_1:0" });
}
}